{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8166e48f-3c2b-4fa2-b508-c17ebfc36083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (4.50.2)\n",
      "Requirement already satisfied: langchain in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (0.3.21)\n",
      "Requirement already satisfied: pypdf2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: sentence-transformers in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (4.0.1)\n",
      "Requirement already satisfied: faiss-cpu in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (1.10.0)\n",
      "Requirement already satisfied: datasets in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (3.4.1)\n",
      "Requirement already satisfied: huggingface_hub in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (0.29.3)\n",
      "Collecting unstructured\n",
      "  Using cached unstructured-0.17.2-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain) (0.3.49)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain) (0.3.19)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: scikit-learn in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: Pillow in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (3.11.14)\n",
      "Collecting chardet (from unstructured)\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Using cached lxml-5.3.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting nltk (from unstructured)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from unstructured) (4.12.3)\n",
      "Collecting emoji (from unstructured)\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: dataclasses-json in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from unstructured) (0.6.7)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Using cached python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Using cached rapidfuzz-3.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: backoff in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from unstructured) (2.2.1)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.31.5-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: wrapt in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from unstructured) (1.16.0)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from unstructured) (6.0.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Using cached python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.20)\n",
      "Requirement already satisfied: soupsieve>1.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from dataclasses-json->unstructured) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six>=1.9 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from html5lib->unstructured) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: click in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from nltk->unstructured) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Using cached olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cryptography>=3.1 (from unstructured-client->unstructured)\n",
      "  Using cached cryptography-44.0.2-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting eval-type-backport>=0.2.0 (from unstructured-client->unstructured)\n",
      "  Using cached eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pypdf>=4.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from unstructured-client->unstructured) (5.4.0)\n",
      "Collecting typing-inspection>=0.4.0 (from unstructured-client->unstructured)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.0)\n",
      "Requirement already satisfied: anyio in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\n",
      "Using cached unstructured-0.17.2-py3-none-any.whl (1.8 MB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Using cached lxml-5.3.1-cp310-cp310-manylinux_2_28_x86_64.whl (5.2 MB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Using cached python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Using cached rapidfuzz-3.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Downloading unstructured_client-0.31.5-py3-none-any.whl (177 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached cryptography-44.0.2-cp39-abi3-manylinux_2_34_x86_64.whl (4.2 MB)\n",
      "Using cached eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Installing collected packages: filetype, typing-inspection, rapidfuzz, python-magic, python-iso639, pydantic-core, olefile, nltk, lxml, langdetect, html5lib, eval-type-backport, emoji, chardet, aiofiles, python-oxmsg, pydantic, cryptography, unstructured-client, unstructured\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.20.1\n",
      "    Uninstalling pydantic_core-2.20.1:\n",
      "      Successfully uninstalled pydantic_core-2.20.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.8.2\n",
      "    Uninstalling pydantic-2.8.2:\n",
      "      Successfully uninstalled pydantic-2.8.2\n",
      "Successfully installed aiofiles-24.1.0 chardet-5.2.0 cryptography-44.0.2 emoji-2.14.1 eval-type-backport-0.2.2 filetype-1.2.0 html5lib-1.1 langdetect-1.0.9 lxml-5.3.1 nltk-3.9.1 olefile-0.47 pydantic-2.10.6 pydantic-core-2.27.2 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.12.2 typing-inspection-0.4.0 unstructured-0.17.2 unstructured-client-0.31.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers langchain pypdf2 sentence-transformers faiss-cpu datasets huggingface_hub unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df5dbcb-4a10-4184-8dad-dd999977eebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 27 12:04:16 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.4     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000               Off | 00000000:01:00.0 Off |                  Off |\n",
      "| 30%   32C    P8              25W / 230W |   7656MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2766506-7036-4d4f-bb25-de3e468d760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (0.3.20)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain_community) (0.3.49)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain_community) (0.3.21)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain_community) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain_community) (3.11.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain_community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain_community) (0.3.19)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (0.3.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "020d516a-288d-44d8-a42e-d29e896f52c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 2335 chunks\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Directory with your PDF files\n",
    "pdf_directory = \"ilovepdf_merged.pdf\" \n",
    "\n",
    "all_text = extract_text_from_pdf(pdf_directory)\n",
    "\n",
    "# Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1250,\n",
    "    chunk_overlap=300,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(all_text)\n",
    "print(f\"Split into {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1cd4d39-a3f8-428d-a291-d127215e69ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1123/3499686264.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Initialize embedding model\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "# Create vector store\n",
    "vector_store = FAISS.from_texts(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a14e832-5d70-41cb-85b8-5d53bf3690e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f9289bd1af48c7a44c979cf7ffa6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/tmp/ipykernel_1123/2017016065.py:27: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Authenticate with HuggingFace\n",
    "login(token=\"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\")  # Replace with your actual token\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_id = \"google/flan-t5-xl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "# Create pipeline with GPU support\n",
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1  # Use GPU if available, else CPU\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=1000,\n",
    "    device=device  # Explicitly set device\n",
    ")\n",
    "\n",
    "# Create HuggingFacePipeline\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# Assuming vector_store is defined earlier\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68be413c-39e2-4f8e-87a0-69a21c7273ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_enhanced_questions(chunk, num_questions=3):\n",
    "    system_prompt = \"\"\"\n",
    "    As an expert legal researcher specializing in Indian land laws, your task is to generate as many possible unique, insightful questions, both short and long based on the provided legal text.\n",
    "\n",
    "    Create questions that:\n",
    "    1. Cover different sections and provisions mentioned in the text\n",
    "    2. Include both factual questions and hypothetical scenarios requiring application of these laws\n",
    "    3. Address potential ambiguities or interpretations in the legal language\n",
    "    4. Connect to relevant case law or precedents if mentioned\n",
    "    5. Explore practical implications for different stakeholders (farmers, property owners, governments, etc.)\n",
    "    6. Consider historical evolution of these laws when applicable\n",
    "    7. Address procedural aspects of land administration\n",
    "    8. Incorporate questions about rights, duties, and remedies\n",
    "\n",
    "    Ensure the questions are of varying complexity:\n",
    "    - Basic: Straightforward factual questions\n",
    "    - Intermediate: Questions requiring understanding of multiple provisions\n",
    "    - Advanced: Questions needing analysis, interpretation, or application to complex scenarios\n",
    "\n",
    "    Format: Number each question and ensure it ends with a question mark.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = system_prompt.format(num_questions=num_questions) + \"\\n\\nLegal Text: \" + chunk\n",
    "\n",
    "    # Generate questions with higher temperature for more creativity\n",
    "    response = pipe(prompt, max_length=2048, do_sample=True, temperature=0.8)\n",
    "    questions_text = response[0]['generated_text']\n",
    "\n",
    "    # Extract questions (numbered items ending with question mark)\n",
    "    import re\n",
    "    questions = re.findall(r'\\d+\\.\\s+(.*?\\?)', questions_text)\n",
    "\n",
    "    # If regex didn't find enough, fall back to line splitting\n",
    "    if len(questions) < num_questions:\n",
    "        lines = questions_text.split('\\n')\n",
    "        questions = [line for line in lines if '?' in line]\n",
    "\n",
    "    # Clean up and ensure quality\n",
    "    clean_questions = []\n",
    "    for q in questions:\n",
    "        q = q.strip()\n",
    "        if q and '?' in q and len(q) > 20:  # More stringent filtering\n",
    "            clean_questions.append(q)\n",
    "\n",
    "    return clean_questions[:num_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29e86695-968f-4257-bc2b-ff8e998e7a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "/tmp/ipykernel_1123/3918924936.py:69: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = qa_chain.run(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/2335 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/2335 chunks\n",
      "Processed 20/2335 chunks\n",
      "Processed 30/2335 chunks\n",
      "Processed 40/2335 chunks\n",
      "Processed 50/2335 chunks\n",
      "Processed 60/2335 chunks\n",
      "Processed 70/2335 chunks\n",
      "Processed 80/2335 chunks\n",
      "Processed 90/2335 chunks\n",
      "Processed 100/2335 chunks\n",
      "Processed 110/2335 chunks\n",
      "Processed 120/2335 chunks\n",
      "Processed 130/2335 chunks\n",
      "Processed 140/2335 chunks\n",
      "Processed 150/2335 chunks\n",
      "Processed 160/2335 chunks\n",
      "Processed 170/2335 chunks\n",
      "Processed 180/2335 chunks\n",
      "Processed 190/2335 chunks\n",
      "Processed 200/2335 chunks\n",
      "Processed 210/2335 chunks\n",
      "Processed 220/2335 chunks\n",
      "Processed 230/2335 chunks\n",
      "Processed 240/2335 chunks\n",
      "Processed 250/2335 chunks\n",
      "Processed 260/2335 chunks\n",
      "Processed 270/2335 chunks\n",
      "Processed 280/2335 chunks\n",
      "Processed 290/2335 chunks\n",
      "Processed 300/2335 chunks\n",
      "Processed 310/2335 chunks\n",
      "Processed 320/2335 chunks\n",
      "Processed 330/2335 chunks\n",
      "Processed 340/2335 chunks\n",
      "Processed 350/2335 chunks\n",
      "Processed 360/2335 chunks\n",
      "Processed 370/2335 chunks\n",
      "Processed 380/2335 chunks\n",
      "Processed 390/2335 chunks\n",
      "Processed 400/2335 chunks\n",
      "Processed 410/2335 chunks\n",
      "Processed 420/2335 chunks\n",
      "Processed 430/2335 chunks\n",
      "Processed 440/2335 chunks\n",
      "Processed 450/2335 chunks\n",
      "Processed 460/2335 chunks\n",
      "Processed 470/2335 chunks\n",
      "Processed 480/2335 chunks\n",
      "Processed 490/2335 chunks\n",
      "Processed 500/2335 chunks\n",
      "Processed 510/2335 chunks\n",
      "Processed 520/2335 chunks\n",
      "Processed 530/2335 chunks\n",
      "Processed 540/2335 chunks\n",
      "Processed 550/2335 chunks\n",
      "Processed 560/2335 chunks\n",
      "Processed 570/2335 chunks\n",
      "Processed 580/2335 chunks\n",
      "Processed 590/2335 chunks\n",
      "Processed 600/2335 chunks\n",
      "Processed 610/2335 chunks\n",
      "Processed 620/2335 chunks\n",
      "Processed 630/2335 chunks\n",
      "Processed 640/2335 chunks\n",
      "Processed 650/2335 chunks\n",
      "Processed 660/2335 chunks\n",
      "Processed 670/2335 chunks\n",
      "Processed 680/2335 chunks\n",
      "Processed 690/2335 chunks\n",
      "Processed 700/2335 chunks\n",
      "Processed 710/2335 chunks\n",
      "Processed 720/2335 chunks\n",
      "Processed 730/2335 chunks\n",
      "Processed 740/2335 chunks\n",
      "Processed 750/2335 chunks\n",
      "Processed 760/2335 chunks\n",
      "Processed 770/2335 chunks\n",
      "Processed 780/2335 chunks\n",
      "Processed 790/2335 chunks\n",
      "Processed 800/2335 chunks\n",
      "Processed 810/2335 chunks\n",
      "Processed 820/2335 chunks\n",
      "Processed 830/2335 chunks\n",
      "Processed 840/2335 chunks\n",
      "Processed 850/2335 chunks\n",
      "Processed 860/2335 chunks\n",
      "Processed 870/2335 chunks\n",
      "Processed 880/2335 chunks\n",
      "Processed 890/2335 chunks\n",
      "Processed 900/2335 chunks\n",
      "Processed 910/2335 chunks\n",
      "Processed 920/2335 chunks\n",
      "Processed 930/2335 chunks\n",
      "Processed 940/2335 chunks\n",
      "Processed 950/2335 chunks\n",
      "Processed 960/2335 chunks\n",
      "Processed 970/2335 chunks\n",
      "Processed 980/2335 chunks\n",
      "Processed 990/2335 chunks\n",
      "Processed 1000/2335 chunks\n",
      "Processed 1010/2335 chunks\n",
      "Processed 1020/2335 chunks\n",
      "Processed 1030/2335 chunks\n",
      "Processed 1040/2335 chunks\n",
      "Processed 1050/2335 chunks\n",
      "Processed 1060/2335 chunks\n",
      "Processed 1070/2335 chunks\n",
      "Processed 1080/2335 chunks\n",
      "Processed 1090/2335 chunks\n",
      "Processed 1100/2335 chunks\n",
      "Processed 1110/2335 chunks\n",
      "Processed 1120/2335 chunks\n",
      "Processed 1130/2335 chunks\n",
      "Processed 1140/2335 chunks\n",
      "Processed 1150/2335 chunks\n",
      "Processed 1160/2335 chunks\n",
      "Processed 1170/2335 chunks\n",
      "Processed 1180/2335 chunks\n",
      "Processed 1190/2335 chunks\n",
      "Processed 1200/2335 chunks\n",
      "Processed 1210/2335 chunks\n",
      "Processed 1220/2335 chunks\n",
      "Processed 1230/2335 chunks\n",
      "Processed 1240/2335 chunks\n",
      "Processed 1250/2335 chunks\n",
      "Processed 1260/2335 chunks\n",
      "Processed 1270/2335 chunks\n",
      "Processed 1280/2335 chunks\n",
      "Processed 1290/2335 chunks\n",
      "Processed 1300/2335 chunks\n",
      "Processed 1310/2335 chunks\n",
      "Processed 1320/2335 chunks\n",
      "Processed 1330/2335 chunks\n",
      "Processed 1340/2335 chunks\n",
      "Processed 1350/2335 chunks\n",
      "Processed 1360/2335 chunks\n",
      "Processed 1370/2335 chunks\n",
      "Processed 1380/2335 chunks\n",
      "Processed 1390/2335 chunks\n",
      "Processed 1400/2335 chunks\n",
      "Processed 1410/2335 chunks\n",
      "Processed 1420/2335 chunks\n",
      "Processed 1430/2335 chunks\n",
      "Processed 1440/2335 chunks\n",
      "Processed 1450/2335 chunks\n",
      "Processed 1460/2335 chunks\n",
      "Processed 1470/2335 chunks\n",
      "Processed 1480/2335 chunks\n",
      "Processed 1490/2335 chunks\n",
      "Processed 1500/2335 chunks\n",
      "Processed 1510/2335 chunks\n",
      "Processed 1520/2335 chunks\n",
      "Processed 1530/2335 chunks\n",
      "Processed 1540/2335 chunks\n",
      "Processed 1550/2335 chunks\n",
      "Processed 1560/2335 chunks\n",
      "Processed 1570/2335 chunks\n",
      "Processed 1580/2335 chunks\n",
      "Processed 1590/2335 chunks\n",
      "Processed 1600/2335 chunks\n",
      "Processed 1610/2335 chunks\n",
      "Processed 1620/2335 chunks\n",
      "Processed 1630/2335 chunks\n",
      "Processed 1640/2335 chunks\n",
      "Processed 1650/2335 chunks\n",
      "Processed 1660/2335 chunks\n",
      "Processed 1670/2335 chunks\n",
      "Processed 1680/2335 chunks\n",
      "Processed 1690/2335 chunks\n",
      "Processed 1700/2335 chunks\n",
      "Processed 1710/2335 chunks\n",
      "Processed 1720/2335 chunks\n",
      "Processed 1730/2335 chunks\n",
      "Processed 1740/2335 chunks\n",
      "Processed 1750/2335 chunks\n",
      "Processed 1760/2335 chunks\n",
      "Processed 1770/2335 chunks\n",
      "Processed 1780/2335 chunks\n",
      "Processed 1790/2335 chunks\n",
      "Processed 1800/2335 chunks\n",
      "Processed 1810/2335 chunks\n",
      "Processed 1820/2335 chunks\n",
      "Processed 1830/2335 chunks\n",
      "Processed 1840/2335 chunks\n",
      "Processed 1850/2335 chunks\n",
      "Processed 1860/2335 chunks\n",
      "Processed 1870/2335 chunks\n",
      "Processed 1880/2335 chunks\n",
      "Processed 1890/2335 chunks\n",
      "Processed 1900/2335 chunks\n",
      "Processed 1910/2335 chunks\n",
      "Processed 1920/2335 chunks\n",
      "Processed 1930/2335 chunks\n",
      "Processed 1940/2335 chunks\n",
      "Processed 1950/2335 chunks\n",
      "Processed 1960/2335 chunks\n",
      "Processed 1970/2335 chunks\n",
      "Processed 1980/2335 chunks\n",
      "Processed 1990/2335 chunks\n",
      "Processed 2000/2335 chunks\n",
      "Processed 2010/2335 chunks\n",
      "Processed 2020/2335 chunks\n",
      "Processed 2030/2335 chunks\n",
      "Processed 2040/2335 chunks\n",
      "Processed 2050/2335 chunks\n",
      "Processed 2060/2335 chunks\n",
      "Processed 2070/2335 chunks\n",
      "Processed 2080/2335 chunks\n",
      "Processed 2090/2335 chunks\n",
      "Processed 2100/2335 chunks\n",
      "Processed 2110/2335 chunks\n",
      "Processed 2120/2335 chunks\n",
      "Processed 2130/2335 chunks\n",
      "Processed 2140/2335 chunks\n",
      "Processed 2150/2335 chunks\n",
      "Processed 2160/2335 chunks\n",
      "Processed 2170/2335 chunks\n",
      "Processed 2180/2335 chunks\n",
      "Processed 2190/2335 chunks\n",
      "Processed 2200/2335 chunks\n",
      "Processed 2210/2335 chunks\n",
      "Processed 2220/2335 chunks\n",
      "Processed 2230/2335 chunks\n",
      "Processed 2240/2335 chunks\n",
      "Processed 2250/2335 chunks\n",
      "Processed 2260/2335 chunks\n",
      "Processed 2270/2335 chunks\n",
      "Processed 2280/2335 chunks\n",
      "Processed 2290/2335 chunks\n",
      "Processed 2300/2335 chunks\n",
      "Processed 2310/2335 chunks\n",
      "Processed 2320/2335 chunks\n",
      "Processed 2330/2335 chunks\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def create_conversation_pair(question, answer, follow_up_probability=0.6):\n",
    "    # Initial question-answer pair\n",
    "    conversation = [\n",
    "        {\"from\": \"human\", \"value\": question},\n",
    "        {\"from\": \"gpt\", \"value\": answer}\n",
    "    ]\n",
    "\n",
    "    # Add follow-up with some probability\n",
    "    if random.random() < follow_up_probability:\n",
    "        # Generate follow-up question based on initial Q&A\n",
    "        follow_up_prompt = f\"\"\"\n",
    "        Based on this conversation:\n",
    "        Q: {question}\n",
    "        A: {answer}\n",
    "\n",
    "        Generate a natural follow-up question that the human might ask.\n",
    "        \"\"\"\n",
    "\n",
    "        follow_up_response = pipe(follow_up_prompt, max_length=1000, do_sample=True, temperature=0.7)\n",
    "        follow_up_question = follow_up_response[0]['generated_text'].strip()\n",
    "\n",
    "        # Clean up the follow-up question\n",
    "        if \":\" in follow_up_question:\n",
    "            follow_up_question = follow_up_question.split(\":\", 1)[1].strip()\n",
    "\n",
    "        # Generate answer to follow-up\n",
    "        follow_up_answer = qa_chain.run(follow_up_question)\n",
    "\n",
    "        # Add to conversation\n",
    "        conversation.append({\"from\": \"human\", \"value\": follow_up_question})\n",
    "        conversation.append({\"from\": \"gpt\", \"value\": follow_up_answer})\n",
    "\n",
    "        # Add one more follow-up with lower probability\n",
    "        if random.random() < 0.5:\n",
    "            second_follow_up_prompt = f\"\"\"\n",
    "            Based on this conversation:\n",
    "            Q1: {question}\n",
    "            A1: {answer}\n",
    "            Q2: {follow_up_question}\n",
    "            A2: {follow_up_answer}\n",
    "\n",
    "            Generate one more natural follow-up question that the human might ask.\n",
    "            \"\"\"\n",
    "\n",
    "            second_follow_up_response = pipe(second_follow_up_prompt, max_length=512)\n",
    "            second_follow_up_question = second_follow_up_response[0]['generated_text'].strip()\n",
    "\n",
    "            # Clean up\n",
    "            if \":\" in second_follow_up_question:\n",
    "                second_follow_up_question = second_follow_up_question.split(\":\", 1)[1].strip()\n",
    "\n",
    "            # Generate answer\n",
    "            second_follow_up_answer = qa_chain.run(second_follow_up_question)\n",
    "\n",
    "            # Add to conversation\n",
    "            conversation.append({\"from\": \"human\", \"value\": second_follow_up_question})\n",
    "            conversation.append({\"from\": \"gpt\", \"value\": second_follow_up_answer})\n",
    "\n",
    "    return conversation\n",
    "\n",
    "# Create dataset\n",
    "dataset = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    questions = generate_enhanced_questions(chunk)\n",
    "    for question in questions:\n",
    "        answer = qa_chain.run(question)\n",
    "        conversation = create_conversation_pair(question, answer)\n",
    "        dataset.append(conversation)\n",
    "\n",
    "    # Print progress\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Processed {i}/{len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a27e14af-3848-4be8-89bb-4fe9ee92bde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'from': 'human',\n",
       "   'value': 'What shall be the procedure when a sharer undertakes to buy?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'the court shall order a valuation of the share or shares in such manner as it may think fit and offer to sell the same to such shareholder at the price so ascertained'},\n",
       "  {'from': 'human', 'value': 'How many shares can a shareholder buy?'},\n",
       "  {'from': 'gpt', 'value': 'tw o or more'},\n",
       "  {'from': 'human',\n",
       "   'value': 'What is the procedure for a shareholder to buy a share?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'the court shall order a valuation of the share or shares in such manner as it may think fit and offer to sell the same to such shareholder at the price so ascertained'}],\n",
       " [{'from': 'human', 'value': 'Where does Section 3 of the Act come?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Repeal of Acts. Saving of certain enactments, incidents, rights, liabilities, etc.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'What is the difference between Section 3 and Section 4 of the Act?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'b) any terms or incidents of any contract or constitution of property which ar e consistent with the provisions of this Act, and ar e allowed by the law for the time being in force :'}],\n",
       " [{'from': 'human',\n",
       "   'value': 'How can a partition suit be initiated against a person who owns a share in a dwelling-house?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Where a share of a dwelling -house belonging to an undivided family has been transferred to a person who is not a member of such family'},\n",
       "  {'from': 'human', 'value': 'Which is the type of partition suit?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Partition suit by transferee of share in dwelling -house'},\n",
       "  {'from': 'human', 'value': 'What is the procedure for a partition suit?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'a division of the property cannot reasonably or conveniently be made, and that a sale of the property and distribution of the proceeds would be more beneficial for all the shareholders'}],\n",
       " [{'from': 'human', 'value': 'What is the scope of the Act?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'In the territories to which this Act extends for the time being the enactments specified in the Schedule hereto annexed shall be repealed to the extent therein mentioned. But nothing'},\n",
       "  {'from': 'human',\n",
       "   'value': 'What is the date of the Indian National Congress?'},\n",
       "  {'from': 'gpt', 'value': 'not enough information'}],\n",
       " [{'from': 'human',\n",
       "   'value': 'What are the provisions that limit the bidding process to the maximum price notified in the government gazette?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Reserved bidding and bidding by shareholders .—(1) Every sale under section 2 shall be subject to a reserved bidding, and the amount of such bidding shall be fixed by the court in such manner as it may think fit and may be varied from time to time.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Is it possible that the court may fix a reserve price for the property before it is auctioned?'},\n",
       "  {'from': 'gpt', 'value': 'Yes'}],\n",
       " [{'from': 'human',\n",
       "   'value': 'How is it deemed that the person who advances the same sum at any bidding at such sale was the bidding of the shareholder?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'If two or more persons, of whom one is a shareholder in the proper ty, respectively advance the same sum at any bidding at such sale, such bidding shall be deemed to be the bidding of the shareholder.'}],\n",
       " [{'from': 'human',\n",
       "   'value': 'How will High Court decide on Sale of property?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'the court shall order a sale of the share or shares to the shareholder who offers to pay the highest price above the valuation made by the court'},\n",
       "  {'from': 'human', 'value': 'Is the sale of a property on marriage grounds?'},\n",
       "  {'from': 'gpt', 'value': 'No'},\n",
       "  {'from': 'human', 'value': 'What is the procedure for sale of property?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'a) if the property be sold under a decree or order of the High Court of Calcutta, Madras or'}],\n",
       " [{'from': 'human',\n",
       "   'value': 'What does it mean to be in the possession of another as benamidar?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': '(A) a transaction or an arrangement — (a) where a property is transferred to, or is held by, a person, and the consideration for such property has been provided, or paid by, a nother person; and (b) the property is held for the immediate or future benefit, direct or indirect, of the person who has provided the consideration, excep t when the property is held by —'},\n",
       "  {'from': 'human', 'value': 'What is a Benamidar?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'a person or a fictitious person, as the case may be, in whose name the benami property is transferred or held'},\n",
       "  {'from': 'human',\n",
       "   'value': 'What is the difference between a benamidar and a benamidar?'},\n",
       "  {'from': 'gpt', 'value': 'a person or a fictitious person'}],\n",
       " [{'from': 'human',\n",
       "   'value': 'What is the term and conditions of the service of the Chairperson and Members of Adjudicating Authority?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'a term not exceeding five years from the date on which they enter upon their office, or until they attain the age of sixty -two years, whichever is earlier and shall not be eligible f or reappointment'}],\n",
       " [{'from': 'human', 'value': 'How can properties be attached?'},\n",
       "  {'from': 'gpt', 'value': 'by act of parties or operation of law'},\n",
       "  {'from': 'human', 'value': 'What does act of attachment mean?'},\n",
       "  {'from': 'gpt', 'value': 'annexed to ownership'},\n",
       "  {'from': 'human',\n",
       "   'value': 'What is the difference between a lease and a leasehold?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'A lease of immoveable proper ty is a transfer of a right to enjoy such property, made for a certain time, express or implied, or in perpetuity, in consideration of a price paid or promised, or of money, a share of crops, service or any other thing of value, to be rendered periodically or on specified occasions to the transferor by the transferee, who accepts the transfer on such terms.'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e6ea350-f40d-4a13-970c-02c053b7e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"indian_land_laws_dataset_final.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f3e3df2-657a-49ee-a35d-2ff11878eff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6cec3583424dd9a3a3f65159eac9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60a100e57244d5ead4a9b4531966b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Khalid02/indian-land-laws-RAG-dataset-authentic/commit/fbc5deb0b188fc62847c4b9d0931ad3c66217261', commit_message='Upload dataset', commit_description='', oid='fbc5deb0b188fc62847c4b9d0931ad3c66217261', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Khalid02/indian-land-laws-RAG-dataset-authentic', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Khalid02/indian-land-laws-RAG-dataset-authentic'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from huggingface_hub import login, HfApi\n",
    "# Create a Dataset object\n",
    "dataset_dict = {\"conversations\": dataset}\n",
    "hf_dataset = Dataset.from_dict(dataset_dict)\n",
    "\n",
    "# Push to Hub\n",
    "hf_dataset.push_to_hub(\"Khalid02/indian-land-laws-RAG-dataset-authentic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ffe4d4-921a-4c65-bb81-4443e30dd2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
